---
title: "MSA Cluster Modeling"
author: "Robert J. DiNapoli"
date: "9/16/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Packages

```{r, results='hide', message=FALSE}
library(here)
library(mclust)
library(raster)
library(rgdal)
library(sp)
library(RColorBrewer)
library(PCAtools)
library(sf)
library(tmap)
library(terra)
library(rgeos)
library(spData)
library(knitr)
```

# Import Data
```{r, results='hide', message=FALSE}

#import raw data
dat_raw <- read.csv(here("data/CommunityData-raw-2015.csv"))
#select columns of interest, removed co2_hhs
dat  <- dat_raw[,c(4:12,14:21)]
#convert to dataframe
dat <- as.data.frame(unclass(dat))
#set rownames to city names
rownames(dat)=dat_raw$ME
# remove any records that have NAs
dat = na.omit(dat)
# convert to z-scores
dat <- as.matrix(scale(dat, center = TRUE, scale = TRUE))
```

# Run Cluster GMM

Assumptions: - MSAs form clusters characterized by a multivariate distribution
             - Model forms: shape, volume, orientation
             - GMM fits a series of models with different forms and numbers of clusters
             - Models with highest probability and fewest parameters selected as most optimal
               - Based on Bayesian Information Criterion (BIC)

```{r}
#run mclust on 1 to 20 clusters
dat_mc <- Mclust(dat, G=c(1:20))
#print summary of model fit
summary(dat_mc)
```

# Model comparison
```{r}
#plot BIC scores of different models
plot(dat_mc, what='BIC')
#zoom in on best-fitting models
plot(dat_mc, what='BIC', ylim=c(-37000,-35000))

#model type VVE chosen as best, with similar BIC scores for 9-12 clusters
#to do additional model comparisons, generate and compare VVE models with 9-12 clusters
dat_mc9 <- Mclust(dat, G=9, modelNames="VVE")
dat_mc10 <- Mclust(dat, G=10, modelNames="VVE")
dat_mc11 <- Mclust(dat, G=11, modelNames="VVE")
dat_mc12 <- Mclust(dat, G=12, modelNames="VVE")

#extract BIC scores
BICs<-c(dat_mc9$BIC[1],dat_mc10$BIC[1],dat_mc11$BIC[1],dat_mc12$BIC[1])
#plot BIC scores
plot(c(9:12),BICs, pch=16, ylab="BIC Score",xlab="Number of Clusters", type='o')
#calculate change in BIC score, since in this method the goal to to maximize BIC
#we calculate change from highest scoring model
delta_BIC <- max(BICs) - BICs
#calculate BIC weights
w_BIC <- round(exp(-0.5*delta_BIC)/sum(exp(-0.5*delta_BIC)), digits=3)
#make table of results
results_table <- cbind.data.frame(clusters=c(9:12),BIC=BICs,delta_BIC,weight=w_BIC)
#order by delta
results_table <- results_table[order(delta_BIC),] 
rownames(results_table)<-NULL
#print table
kable(results_table[1:4], caption = "Model Comparison")
```

# Extract and map cluster classifications
```{r}
#extract classifications, e.g., which MSA belongs to which cluster, write to CSV
write.csv(dat_mc10$classification,file=here("results/cluster_assignment.csv"))
data<-read.csv("results/cluster_assignment.csv")

#import shapefile
msa_Boundary <-readOGR(here("data/MSA"),"tl_2015_us_cbsa") 
#merge them
merged <- merge(msa_Boundary,data,by.x="NAME",by.y="X")
#remove any cases MSAs with no cluster assignments
merged_clean <- merged[!is.na(merged$x),]
#convert x to factor
merged_clean$Cluster <- as.factor(merged_clean$x)
#convert to sf object
cluster_sf <- st_as_sf(merged_clean)
#make us map
us_map <- tm_shape(us_states) + tm_borders()
#combine them
cluster_map <- tm_shape(cluster_sf) + tm_fill(col="Cluster", palette="Spectral")
#plot them
us_map + cluster_map
```

# Examine how clusters score in different metrics
```{r, results='hide',message=FALSE}
#new data frame
dat_clust <- as.data.frame(dat)
#add names
dat_clust$ME <- rownames(dat)
rownames(dat_clust) <- NULL
#merge in cluster assignments
dat_clust <- merge(dat_clust,data,by.x="ME",by.y="X")
#calculate cluster means for different variables
c1m <- data.frame(one=colMeans(subset(dat_clust, x=="1")[2:18]))
c2m <- data.frame(two=colMeans(subset(dat_clust, x=="2")[2:18]))
c3m <- data.frame(three=colMeans(subset(dat_clust, x=="3")[2:18]))
c4m <- data.frame(four=colMeans(subset(dat_clust, x=="4")[2:18]))
c5m <- data.frame(five=colMeans(subset(dat_clust, x=="5")[2:18]))
c6m <- data.frame(six=colMeans(subset(dat_clust, x=="6")[2:18]))
c7m <- data.frame(seven=colMeans(subset(dat_clust, x=="7")[2:18]))
c8m <- data.frame(eight=colMeans(subset(dat_clust, x=="8")[2:18]))
c9m <- data.frame(nine=colMeans(subset(dat_clust, x=="9")[2:18]))
c10m <- data.frame(ten=colMeans(subset(dat_clust, x=="10")[2:18]))
cluster_means <- cbind.data.frame(c1m,c2m,c3m,c4m,c5m,c6m,c7m,c8m, c9m, c10m)
cluster_means$variable <- row.names(cluster_means)
rownames(cluster_means) <- NULL
```

```{r, fig.width=30,fig.height=15}
#boxplots of scores for clusters
par(mfrow=c(2,5), mar=c(2.5,5,2.5,3))
boxplot(subset(dat_clust, x=="1")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 1")
boxplot(subset(dat_clust, x=="2")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 2")
boxplot(subset(dat_clust, x=="3")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 3")
boxplot(subset(dat_clust, x=="4")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 4")
boxplot(subset(dat_clust, x=="5")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 5")
boxplot(subset(dat_clust, x=="6")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 6")
boxplot(subset(dat_clust, x=="7")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 7")
boxplot(subset(dat_clust, x=="8")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 8")
boxplot(subset(dat_clust, x=="9")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 9")
boxplot(subset(dat_clust, x=="10")[2:18], horizontal=T, las=1, ylim=c(-4,4), main="Cluster 10")
par(mfrow=c(1,1))
```

```{r, fig.width=30,fig.height=15}
#dotplots of cluster mean values
par(mfrow=c(2,5))
dotchart(cluster_means$one, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 1', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$two, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 2', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$three, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 3', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$four, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 4', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$five, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 5', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$six, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 6', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$seven, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 7', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$eight, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 8', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$nine, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 9', pch=16)
abline(v=0, lwd=2)
dotchart(cluster_means$ten, labels=cluster_means$variable,xlim=c(-2,2), main='Cluster 10', pch=16)
abline(v=0, lwd=2)
par(mfrow=c(1,1))
```

# Which MSAs best characterize their cluster?
```{r,echo=F}
cluster1 <- data.frame(subset(dat_clust, x=="1"))
cluster2 <- data.frame(subset(dat_clust, x=="2"))
cluster3 <- data.frame(subset(dat_clust, x=="3"))
cluster4 <- data.frame(subset(dat_clust, x=="4"))
cluster5 <- data.frame(subset(dat_clust, x=="5"))
cluster6 <- data.frame(subset(dat_clust, x=="6"))
cluster7 <- data.frame(subset(dat_clust, x=="7"))
cluster8 <- data.frame(subset(dat_clust, x=="8"))
cluster9 <- data.frame(subset(dat_clust, x=="9"))
cluster10 <- data.frame(subset(dat_clust, x=="10"))

#function to compute smallest combined absolute difference from mean
Average_MSA_inClust <- function(x) {
  output = data.frame(Name=x$ME)
  for (i in 2:ncol(x)) {
    output[[i]] <- abs(x[[i]] - mean(x[[i]]))
  }
  output$s_diff = rowSums(output[2:ncol(output)])
  cluster_average = output[which.min(output$s_diff),]
  return(cluster_average)
}

cluster1_average <- Average_MSA_inClust(cluster1)
cluster2_average <- Average_MSA_inClust(cluster2)
cluster3_average <- Average_MSA_inClust(cluster3)
cluster4_average <- Average_MSA_inClust(cluster4)
cluster5_average <- Average_MSA_inClust(cluster5)
cluster6_average <- Average_MSA_inClust(cluster6)
cluster7_average <- Average_MSA_inClust(cluster7)
cluster8_average <- Average_MSA_inClust(cluster8)
cluster9_average <- Average_MSA_inClust(cluster9)
cluster10_average <- Average_MSA_inClust(cluster10)

typical_members <- data.frame(Cluster=c(1:10), Name=c(cluster1_average$Name,
                              cluster2_average$Name,
                              cluster3_average$Name,
                              cluster4_average$Name,
                              cluster5_average$Name,
                              cluster6_average$Name,
                              cluster7_average$Name,
                              cluster8_average$Name,
                              cluster9_average$Name,
                              cluster10_average$Name))

kable(typical_members, caption = "Typical members of each cluster")
```

# Which cluster scores the best on the different metrics?
```{r, echo=F}
##########################
#Most sustainable cluster

#rotate columns and rows
cluster_means_t <- cluster_means[1:10]
row.names(cluster_means_t) <- cluster_means$variable
cluster_means_t <- data.frame(t(cluster_means_t))
cluster_means_t$cluster <- row.names(cluster_means_t)
row.names(cluster_means_t) <- NULL

#clusters scoring the best in the different metrics
best_air <- cluster_means_t[which.max(cluster_means_t$AQI_Good),]
best_edu <- cluster_means_t[which.max(cluster_means_t$Bachelor_Over_25),]
best_pov <- cluster_means_t[which.min(cluster_means_t$Per_Poverty),]
best_ineq <- cluster_means_t[which.min(cluster_means_t$Gini),]
best_hous <- cluster_means_t[which.min(cluster_means_t$Per_Sev_Hous),]
best_stream <- cluster_means_t[which.min(cluster_means_t$Xstreamlengthimpaired),]
best_land <- cluster_means_t[which.max(cluster_means_t$Per_Avg_Land_Cov),]
best_health <- cluster_means_t[which.min(cluster_means_t$poor_health_percent),]
best_water <- cluster_means_t[which.min(cluster_means_t$Z_Water_Index),]
low_index_black <- cluster_means_t[which.min(cluster_means_t$Index_Black),]
low_index_asian <- cluster_means_t[which.min(cluster_means_t$Index_Asian),]
low_index_latino <- cluster_means_t[which.min(cluster_means_t$Index_Latino),]
best_emissions <- cluster_means_t[which.min(cluster_means_t$GHG_Percap),]
best_employmet <- cluster_means_t[which.min(cluster_means_t$UNEMPLOY),]
best_food <- cluster_means_t[which.min(cluster_means_t$FOOD_INS),]
best_crime <- cluster_means_t[which.min(cluster_means_t$VIO_CRIME),]


most_sustainable_clusters <- data.frame(Metric=c(colnames(cluster_means_t[c(1:4,6:17)])),
                                        Cluster=c(
                                        best_air$cluster,
                                        best_edu$cluster,
                                        best_pov$cluster,
                                        best_ineq$cluster,
                                        best_hous$cluster,
                                        best_stream$cluster,
                                        best_land$cluster,
                                        best_health$cluster,
                                        best_water$cluster,
                                        low_index_black$cluster,
                                        low_index_asian$cluster,
                                        low_index_latino$cluster,
                                        best_emissions$cluster,
                                        best_employmet$cluster,
                                        best_food$cluster,
                                        best_crime$cluster))

kable(most_sustainable_clusters)
```


# Examine cluster patterns with PCA

## Note: adjusting values for variables so that high='good' and low='bad' for all variables
```{r}
dat_clust_adj <- dat_clust
dat_clust_adj$Per_Poverty <- dat_clust$Per_Poverty * -1
dat_clust_adj$Gini <- dat_clust$Gini * -1
dat_clust_adj$Per_Sev_Hous <- dat_clust$Per_Sev_Hous * -1
dat_clust_adj$Xstreamlengthimpaired <- dat_clust$Xstreamlengthimpaired * -1
dat_clust_adj$poor_health_percent <- dat_clust$poor_health_percent * -1
dat_clust_adj$Z_Water_Index <- dat_clust$Z_Water_Index * -1
dat_clust_adj$Index_Black <- dat_clust$Index_Black * -1
dat_clust_adj$Index_Asian <- dat_clust$Index_Asian * -1
dat_clust_adj$Index_Latino <- dat_clust$Index_Latino * -1

cluster1a <- data.frame(subset(dat_clust_adj, x=="1"))
cluster2a <- data.frame(subset(dat_clust_adj, x=="2"))
cluster3a <- data.frame(subset(dat_clust_adj, x=="3"))
cluster4a <- data.frame(subset(dat_clust_adj, x=="4"))
cluster5a <- data.frame(subset(dat_clust_adj, x=="5"))
cluster6a <- data.frame(subset(dat_clust_adj, x=="6"))
cluster7a <- data.frame(subset(dat_clust_adj, x=="7"))
cluster8a <- data.frame(subset(dat_clust_adj, x=="8"))
cluster9a <- data.frame(subset(dat_clust_adj, x=="9"))
cluster10a <- data.frame(subset(dat_clust_adj, x=="10"))
```

## Perform PCA on individual clusters

```{r,fig.width=12,fig.height=8}
#PCA cluster 1
c1_PCA <- pca(cluster1a[2:18],transposed = T) #rotate table and only use numeric columns
#scree plot
screeplot(c1_PCA, title="Scree plot Cluster 1") 
#elbow method of estimating important components
findElbowPoint(c1_PCA$variance) 
#biplot for PC1 and PC2
biplot(c1_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 1')
#loadings for components
plotloadings(c1_PCA, title="Cluster 1")
```

```{r, fig.width=12, fig.height=8}
#PCA cluster 2
c2_PCA <- pca(cluster2a[2:18],transposed = T)
screeplot(c2_PCA)
findElbowPoint(c2_PCA$variance)
biplot(c2_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 2')
plotloadings(c2_PCA, title="Cluster 2")

#PCA cluster 3
c3_PCA <- pca(cluster3a[2:18],transposed = T)
screeplot(c3_PCA)
findElbowPoint(c3_PCA$variance)
biplot(c3_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 3')
plotloadings(c3_PCA, title="Cluster 3")

#PCA cluster 4
c4_PCA <- pca(cluster4a[2:18],transposed = T)
screeplot(c4_PCA)
findElbowPoint(c4_PCA$variance)
biplot(c4_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 4')
plotloadings(c4_PCA, title="Cluster 4")

#PCA cluster 5
c5_PCA <- pca(cluster5a[2:18],transposed = T)
screeplot(c5_PCA)
findElbowPoint(c5_PCA$variance)
biplot(c5_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 5')
plotloadings(c5_PCA, title="Cluster 5")

#PCA cluster 6
c6_PCA <- pca(cluster6a[2:18],transposed = T)
screeplot(c6_PCA)
findElbowPoint(c6_PCA$variance)
biplot(c6_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 6')
plotloadings(c6_PCA, title="Cluster 6")

#PCA cluster 7
c7_PCA <- pca(cluster7a[2:18],transposed = T)
screeplot(c7_PCA)
findElbowPoint(c7_PCA$variance)
biplot(c7_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 7')
plotloadings(c7_PCA, title="Cluster 7")

#PCA cluster 8
c8_PCA <- pca(cluster8a[2:18],transposed = T)
screeplot(c8_PCA)
findElbowPoint(c8_PCA$variance)
biplot(c8_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 8')
plotloadings(c8_PCA, title="Cluster 8")

#PCA cluster 9
c9_PCA <- pca(cluster9a[2:18],transposed = T)
screeplot(c9_PCA)
findElbowPoint(c9_PCA$variance)
biplot(c9_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 9')
plotloadings(c9_PCA, title="Cluster 9")

#PCA cluster 10
c10_PCA <- pca(cluster10a[2:18],transposed = T)
screeplot(c10_PCA)
findElbowPoint(c10_PCA$variance)
biplot(c10_PCA, showLoadings = T, showLoadingsNames = T, hline=0,vline=0, title='Cluster 10')
plotloadings(c10_PCA, title="Cluster 10")
```



# Dimension reduction
```{r, fig.width=6,fig.height=4}
#run discriminant analysis on clusters
DR <- MclustDR(dat_mc10, lambda = 1) #setting lambda to 1 gives most separating directions
summary(DR)

#plot eigenvalues
plot(c(1:17),DR$evalues,ylab="eigenvalues", xlab="component", type="o", pch=16)

```

```{r, fig.width=30,fig.height=15}
#plot all pairs of combinations
plot(DR, what='pairs',symbols=c("1","2","3","4","5","6","7","8","9","10"),
     colors=c("red","blue","green","goldenrod2","violet","brown","black","grey30","slateblue2","seagreen3"))
```

```{r, fig.width=15,fig.height=10}
#plot directions for variables
Directions <- data.frame(d1=DR$basis[,1],d2=DR$basis[,2],
                         d3=DR$basis[,3],d4=DR$basis[,4],
                         d5=DR$basis[,5],d6=DR$basis[,6],
                         d7=DR$basis[,7],d8=DR$basis[,8],
                         d9=DR$basis[,9],var=rownames(DR$basis))

par(mfrow=c(3,3))
dotchart(Directions$d1, labels=Directions$var, pch=16, main="Dir1", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
dotchart(Directions$d2, labels=Directions$var, pch=16, main="Dir2", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
dotchart(Directions$d3, labels=Directions$var, pch=16, main="Dir3", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
dotchart(Directions$d4, labels=Directions$var, pch=16, main="Dir4", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
dotchart(Directions$d5, labels=Directions$var, pch=16, main="Dir5", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
dotchart(Directions$d6, labels=Directions$var, pch=16, main="Dir6", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
dotchart(Directions$d7, labels=Directions$var, pch=16, main="Dir7", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
dotchart(Directions$d8, labels=Directions$var, pch=16, main="Dir8", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
dotchart(Directions$d9, labels=Directions$var, pch=16, main="Dir9", xlim=c(-0.6,0.6))
abline(v=0, lwd=2)
abline(v=c(0.1,-0.1),lty=2)
par(mfrow=c(1,1))
```

